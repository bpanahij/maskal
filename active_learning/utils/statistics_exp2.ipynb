{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical analysis - experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from csv import reader\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to collect all csv-files in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_csv_files(resultsdir):\n",
    "    csv_files = []\n",
    "\n",
    "    if os.path.isdir(resultsdir):\n",
    "        for root, dirs, files in list(os.walk(resultsdir)):\n",
    "            for name in files:\n",
    "                subdir = root.split(resultsdir)\n",
    "                all('' == s for s in subdir)\n",
    "                \n",
    "                if subdir[1].startswith('/'):\n",
    "                    subdirname = subdir[1][1:]\n",
    "                else:\n",
    "                    subdirname = subdir[1]\n",
    "\n",
    "                if name.lower().endswith('.csv'):\n",
    "                    if all('' == s for s in subdir):\n",
    "                        csv_files.append(name)\n",
    "                    else:\n",
    "                        csv_files.append(os.path.join(subdirname, name))\n",
    "    \n",
    "        csv_files.sort()\n",
    "\n",
    "    return csv_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get all unique combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_combinations(csv_files):\n",
    "    unique_combinations = []\n",
    "    for c in range(len(csv_files)):\n",
    "        csv_file = csv_files[c]\n",
    "        splits = csv_file.split(\"/\")\n",
    "        run_no = splits[0].split(\"run\")[-1]\n",
    "        sam_mt = splits[1].split(\"_\")[0]\n",
    "        unc_mt = splits[1].split(\"_\")[1]\n",
    "        prob = splits[1].split(\"_\")[2]\n",
    "        fwp = splits[1].split(\"_\")[3]\n",
    "        sam_sz = splits[1].split(\"_\")[4]\n",
    "        \n",
    "        if unc_mt == 'mean':\n",
    "            unc_mt = 'average'\n",
    "        \n",
    "        unique_combination = sam_mt + '_' + unc_mt + '_' + prob + '_' + fwp + '_' + sam_sz\n",
    "        unique_combinations.append(unique_combination)\n",
    "    return list(set(unique_combinations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the csv-files and store the data in a pandas-dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampling_method</th>\n",
       "      <th>certainty_method</th>\n",
       "      <th>dropout_probability</th>\n",
       "      <th>number_forward_passes</th>\n",
       "      <th>sampling_size</th>\n",
       "      <th>sampling_frequency</th>\n",
       "      <th>unique_combination</th>\n",
       "      <th>run</th>\n",
       "      <th>number_images</th>\n",
       "      <th>mAP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uncertainty</td>\n",
       "      <td>average</td>\n",
       "      <td>0.25</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>24.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uncertainty</td>\n",
       "      <td>average</td>\n",
       "      <td>0.25</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>29.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uncertainty</td>\n",
       "      <td>average</td>\n",
       "      <td>0.25</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uncertainty</td>\n",
       "      <td>average</td>\n",
       "      <td>0.25</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>39.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uncertainty</td>\n",
       "      <td>average</td>\n",
       "      <td>0.25</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>41.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>uncertainty</td>\n",
       "      <td>average</td>\n",
       "      <td>0.25</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2300</td>\n",
       "      <td>52.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>uncertainty</td>\n",
       "      <td>average</td>\n",
       "      <td>0.25</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2350</td>\n",
       "      <td>58.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>uncertainty</td>\n",
       "      <td>average</td>\n",
       "      <td>0.25</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2400</td>\n",
       "      <td>58.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>uncertainty</td>\n",
       "      <td>average</td>\n",
       "      <td>0.25</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2450</td>\n",
       "      <td>58.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>uncertainty</td>\n",
       "      <td>average</td>\n",
       "      <td>0.25</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2500</td>\n",
       "      <td>58.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>470 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sampling_method certainty_method  dropout_probability  \\\n",
       "0       uncertainty          average                 0.25   \n",
       "1       uncertainty          average                 0.25   \n",
       "2       uncertainty          average                 0.25   \n",
       "3       uncertainty          average                 0.25   \n",
       "4       uncertainty          average                 0.25   \n",
       "..              ...              ...                  ...   \n",
       "465     uncertainty          average                 0.25   \n",
       "466     uncertainty          average                 0.25   \n",
       "467     uncertainty          average                 0.25   \n",
       "468     uncertainty          average                 0.25   \n",
       "469     uncertainty          average                 0.25   \n",
       "\n",
       "    number_forward_passes sampling_size sampling_frequency unique_combination  \\\n",
       "0                      20           100                 24                  0   \n",
       "1                      20           100                 24                  0   \n",
       "2                      20           100                 24                  0   \n",
       "3                      20           100                 24                  0   \n",
       "4                      20           100                 24                  0   \n",
       "..                    ...           ...                ...                ...   \n",
       "465                    20            50                 48                  2   \n",
       "466                    20            50                 48                  2   \n",
       "467                    20            50                 48                  2   \n",
       "468                    20            50                 48                  2   \n",
       "469                    20            50                 48                  2   \n",
       "\n",
       "    run number_images   mAP  \n",
       "0     1           100  24.9  \n",
       "1     1           200  29.5  \n",
       "2     1           300  35.5  \n",
       "3     1           400  39.2  \n",
       "4     1           500  41.5  \n",
       "..   ..           ...   ...  \n",
       "465   5          2300  52.9  \n",
       "466   5          2350  58.7  \n",
       "467   5          2400  58.7  \n",
       "468   5          2450  58.7  \n",
       "469   5          2500  58.7  \n",
       "\n",
       "[470 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsdir = \"results/exp2\"\n",
    "two_up = os.path.abspath(os.path.join(os.getcwd(),\"../..\"))\n",
    "resultsdir = os.path.join(two_up, resultsdir)\n",
    "csv_files = list_csv_files(resultsdir)\n",
    "\n",
    "clmns = [\"sampling_method\", \"certainty_method\", \"dropout_probability\", \"number_forward_passes\", \"sampling_size\", \"sampling_frequency\", \"unique_combination\", \"run\", \"number_images\", \"mAP\"]\n",
    "df = pd.DataFrame(columns=clmns)\n",
    "unique_combinations = get_unique_combinations(csv_files)\n",
    "ucs = [None] * len(unique_combinations)\n",
    "\n",
    "for c in range(len(csv_files)):\n",
    "    csv_file = csv_files[c]\n",
    "    splits = csv_file.split(\"/\")\n",
    "    run_no = splits[0].split(\"run\")[-1]\n",
    "    sam_mt = splits[1].split(\"_\")[0]\n",
    "    unc_mt = splits[1].split(\"_\")[1]\n",
    "    prob = splits[1].split(\"_\")[2]\n",
    "    fwp = splits[1].split(\"_\")[3]\n",
    "    sam_sz = splits[1].split(\"_\")[4]\n",
    "    sam_freq = 2400 / int(sam_sz)\n",
    "    \n",
    "    if unc_mt == 'mean':\n",
    "        unc_mt = 'average'\n",
    "        \n",
    "    unique_combination = sam_mt + '_' + unc_mt + '_' + prob + '_' + fwp + '_' + sam_sz\n",
    "    uc_id = unique_combinations.index(unique_combination) \n",
    "    ucs[uc_id] = unique_combination\n",
    "\n",
    "    with open(os.path.join(resultsdir, csv_file), 'r') as read_obj:\n",
    "        csv_reader = reader(read_obj)\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            data = [sam_mt, unc_mt, float(prob), int(fwp), int(sam_sz), int(sam_freq), int(uc_id), int(run_no), int(row[0]), float(row[1])]\n",
    "            df.loc[len(df)] = data\n",
    "            \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sampled images: 100\n",
      "\n",
      "                      mAP\n",
      "sampling_frequency       \n",
      "6                   22.44\n",
      "12                  22.44\n",
      "24                  22.44\n",
      "48                  22.44\n",
      "                     Anova\n",
      "================================================\n",
      "                   F Value Num DF  Den DF Pr > F\n",
      "------------------------------------------------\n",
      "sampling_frequency -1.3333 3.0000 12.0000 1.0000\n",
      "================================================\n",
      "\n",
      "Number of sampled images: 500\n",
      "\n",
      "                      mAP\n",
      "sampling_frequency       \n",
      "6                   36.74\n",
      "12                  42.24\n",
      "24                  41.62\n",
      "48                  40.86\n",
      "                     Anova\n",
      "================================================\n",
      "                   F Value Num DF  Den DF Pr > F\n",
      "------------------------------------------------\n",
      "sampling_frequency  5.5559 3.0000 12.0000 0.0126\n",
      "================================================\n",
      "\n",
      "Number of sampled images: 900\n",
      "\n",
      "                      mAP\n",
      "sampling_frequency       \n",
      "6                   48.42\n",
      "12                  50.50\n",
      "24                  48.84\n",
      "48                  47.50\n",
      "                     Anova\n",
      "================================================\n",
      "                   F Value Num DF  Den DF Pr > F\n",
      "------------------------------------------------\n",
      "sampling_frequency  2.3963 3.0000 12.0000 0.1191\n",
      "================================================\n",
      "\n",
      "Number of sampled images: 1300\n",
      "\n",
      "                      mAP\n",
      "sampling_frequency       \n",
      "6                   55.64\n",
      "12                  55.18\n",
      "24                  50.30\n",
      "48                  50.96\n",
      "                     Anova\n",
      "================================================\n",
      "                   F Value Num DF  Den DF Pr > F\n",
      "------------------------------------------------\n",
      "sampling_frequency 16.0777 3.0000 12.0000 0.0002\n",
      "================================================\n",
      "\n",
      "Number of sampled images: 1700\n",
      "\n",
      "                      mAP\n",
      "sampling_frequency       \n",
      "6                   57.54\n",
      "12                  57.90\n",
      "24                  51.70\n",
      "48                  53.08\n",
      "                     Anova\n",
      "================================================\n",
      "                   F Value Num DF  Den DF Pr > F\n",
      "------------------------------------------------\n",
      "sampling_frequency 19.0041 3.0000 12.0000 0.0001\n",
      "================================================\n",
      "\n",
      "Number of sampled images: 2100\n",
      "\n",
      "                      mAP\n",
      "sampling_frequency       \n",
      "6                   60.18\n",
      "12                  58.86\n",
      "24                  56.08\n",
      "48                  54.30\n",
      "                     Anova\n",
      "================================================\n",
      "                   F Value Num DF  Den DF Pr > F\n",
      "------------------------------------------------\n",
      "sampling_frequency 12.8449 3.0000 12.0000 0.0005\n",
      "================================================\n",
      "\n",
      "Number of sampled images: 2500\n",
      "\n",
      "                      mAP\n",
      "sampling_frequency       \n",
      "6                   60.52\n",
      "12                  59.46\n",
      "24                  57.30\n",
      "48                  56.72\n",
      "                     Anova\n",
      "================================================\n",
      "                   F Value Num DF  Den DF Pr > F\n",
      "------------------------------------------------\n",
      "sampling_frequency  6.4031 3.0000 12.0000 0.0078\n",
      "================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numimg = [100, 500, 900, 1300, 1700, 2100, 2500]\n",
    "df1 = df.loc[df['number_images'].isin(numimg)]\n",
    "num_img = df1[\"number_images\"].values.ravel()\n",
    "num_img = pd.unique(num_img)\n",
    "\n",
    "for ni in range(len(num_img)):\n",
    "    cur_num_img = num_img[ni]\n",
    "    sel = df1[df1[\"number_images\"] == cur_num_img]\n",
    "    print(\"Number of sampled images: {:d}\\n\".format(cur_num_img))\n",
    "    mean = sel.groupby(['sampling_frequency']).mean().drop(columns=['dropout_probability'])\n",
    "    print(mean)\n",
    "    \n",
    "    aovrm = AnovaRM(data=sel, depvar='mAP', subject='run', within=['sampling_frequency'], aggregate_func='mean')\n",
    "    res = aovrm.fit()\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('/mnt/nvme2n1p2/PieterBlok/PhD/Paper 04 - Active Learning/Results/exp2/exp2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('maskAL': conda)",
   "language": "python",
   "name": "python38864bitmaskalconda5eeceee4b8524f519f0da7eea7fb970c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
