# Parameters for maskAL
# git revert 0552850
# python maskAL.py --config active_learning/config/maskAL_exp1_run2.yaml
# explanation can be found here: https://github.com/pieterblok/maskal

# folders
weightsroot: "./weights"
resultsroot: "./results"
dataroot: "./datasets/exp1/run2"
traindir: "./datasets/train"
valdir: "./datasets/val"
testdir: "./datasets/test01"

# training-parameters
cuda_visible_devices: '1'
classes: ['healthy', 'damaged', 'matured', 'cateye', 'headrot']
transfer_learning_on_previous_models: True
train_complete_trainset: False
duplicate_initial_model: False
learning_rate: 0.01
warmup_iterations: 500
train_iterations_base: 2500
train_iterations_step_size: 2500
step_image_number: 500
step_ratios: [0.5, 0.8]
eval_period: 500
checkpoint_period: -1
weight_decay: 0.0001
learning_policy: 'steps_with_decay'
gamma: 0.1
train_batch_size: 2
num_workers: 2

# train-sampler
train_sampler: "RepeatFactorTrainingSampler"
minority_classes: ['damaged', 'matured', 'cateye', 'headrot']
repeat_factor_smallest_class: 1.5

# evaluation-parameters
confidence_threshold: 0.5
nms_threshold: 0.01

# active-learning sampling
experiment_name: 'exp1/run2'
strategies: 'uncertainty'
mode: ['mean', 'mean', 'min', 'min', 'mean', 'mean', 'min', 'min', 'mean', 'mean', 'min', 'min']
initial_datasize: 100
pool_size: 200
equal_pool_size: True
loops: 12
dropout_probability: [0.25, 0.25, 0.25, 0.25, 0.50, 0.50, 0.50, 0.50, 0.75, 0.75, 0.75, 0.75]
mcd_iterations: [20, 40, 20, 40, 20, 40, 20, 40, 20, 40, 20, 40]
dropout_method: 'head'
al_batch_size: 1
iou_thres: 0.5
resume: False
auto_annotate: False
export_format: labelme
supervisely_meta_json: "./datasets/meta.json"
